\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\select@language{english}
\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\select@language{english}}
\citation{WETZ_TOMO}
\citation{WETZ_TENS}
\citation{WETZ_TOMO}
\citation{LEVO_LFREN}
\citation{WETZ_TOMO}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:perspective_shifted_projections}{{1a}{2}{Perspective projections, images are shifted\relax }{figure.caption.2}{}}
\newlabel{sub@fig:perspective_shifted_projections}{{a}{2}{Perspective projections, images are shifted\relax }{figure.caption.2}{}}
\newlabel{fig:sheared_projections}{{1b}{2}{Sheared projections, cameras have a common image plane\relax }{figure.caption.2}{}}
\newlabel{sub@fig:sheared_projections}{{b}{2}{Sheared projections, cameras have a common image plane\relax }{figure.caption.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Different methods to capture a lightfield\relax }}{2}{figure.caption.2}}
\@writefile{toc}{\contentsline {section}{\numberline {1}Related work}{2}{section.1}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Types of light fields}{2}{section.2}}
\newlabel{sec:lftypes}{{2}{2}{Types of light fields}{section.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Notation}{2}{section.3}}
\@writefile{toc}{\contentsline {section}{\numberline {4}A first implementation for orthographic projections}{2}{section.4}}
\newlabel{sec:first_implementation}{{4}{2}{A first implementation for orthographic projections}{section.4}{}}
\newlabel{eq:core_problem}{{1}{2}{A first implementation for orthographic projections}{equation.4.1}{}}
\citation{CONV_SART}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces The rays captured by camera $i$ using orthographic projection. All rays from one camera have the same angle $\theta _i$, which is measured relative to the surface normal of the layers. $x_6^i$, $s_5^2$ and $s_7^1$ denote the intersections of the ray with the camera sensor and the layers. $d_L$ is the distance between the layers.\relax }}{3}{figure.caption.3}}
\newlabel{fig:orthographic_cameras_layers_sketch}{{2}{3}{The rays captured by camera $i$ using orthographic projection. All rays from one camera have the same angle $\theta _i$, which is measured relative to the surface normal of the layers. $x_6^i$, $s_5^2$ and $s_7^1$ denote the intersections of the ray with the camera sensor and the layers. $d_L$ is the distance between the layers.\relax }{figure.caption.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Moving to light fields of type 1}{3}{section.5}}
\newlabel{fig:problem_camera_to_layers}{{3a}{4}{Two rays hitting a cameras sensor in neighbouring pixels. The two rays intersect with the layer pixels, with multiple pixels in between.\relax }{figure.caption.4}{}}
\newlabel{sub@fig:problem_camera_to_layers}{{a}{4}{Two rays hitting a cameras sensor in neighbouring pixels. The two rays intersect with the layer pixels, with multiple pixels in between.\relax }{figure.caption.4}{}}
\newlabel{fig:problem_layers_to_camera}{{3b}{4}{Rays coming from four different layer pixels and hitting the same sensor pixel in the camera.\relax }{figure.caption.4}{}}
\newlabel{sub@fig:problem_layers_to_camera}{{b}{4}{Rays coming from four different layer pixels and hitting the same sensor pixel in the camera.\relax }{figure.caption.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Problems that can arise from different resolution in image- and layer space.\relax }}{4}{figure.caption.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Approach 1: From camera pixels to layer pixels}{4}{subsection.5.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Approach 2: Converting the light field}{4}{subsection.5.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Approach 3: From layer pixels to camera pixels}{4}{subsection.5.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Two rays (red) intersecting the first layer (blue) at position $s_i^1$. The rays are captured by different cameras at positions $u_1$ and $u_2$, hitting the camera sensor at locations $x_j^1$ and $x_k^2$. The dotted lines represent the field of view of each camera.\relax }}{5}{figure.caption.5}}
\newlabel{fig:cameras_layers_sketch}{{4}{5}{Two rays (red) intersecting the first layer (blue) at position $s_i^1$. The rays are captured by different cameras at positions $u_1$ and $u_2$, hitting the camera sensor at locations $x_j^1$ and $x_k^2$. The dotted lines represent the field of view of each camera.\relax }{figure.caption.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Creating synthetic light fields}{5}{section.6}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Review of the two implementations}{6}{section.7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1}Orthographic projections}{6}{subsection.7.1}}
\newlabel{fig:P_orthographic_full}{{5a}{6}{Full matrix.\relax }{figure.caption.6}{}}
\newlabel{sub@fig:P_orthographic_full}{{a}{6}{Full matrix.\relax }{figure.caption.6}{}}
\newlabel{fig:P_orthographic_section}{{5b}{6}{The upper left section of the matrix.\relax }{figure.caption.6}{}}
\newlabel{sub@fig:P_orthographic_section}{{b}{6}{The upper left section of the matrix.\relax }{figure.caption.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces The structure of the propagation matrix $P$. The non-zero elements are marked as blue.\relax }}{6}{figure.caption.6}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Optimization for three layers. The light field has an angular resolution of $7\times 7$ views. The blur in the reconstruction is also in the original light field.\relax }}{7}{figure.caption.7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2}Perspective projections}{8}{subsection.7.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Optimization for three layers. The light field has an angular resolution of $5\times 5$ views. Parameters: $z = 8$, $d_c = \left ( 0.05, 0.05 \right )$, $\text  {fov} = \left ( 60^\circ , 45^\circ \right )$, $d_L = 1.5$\relax }}{9}{figure.caption.8}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Optimization for three layers. The light field has an angular resolution of $5\times 5$ views.\relax }}{10}{figure.caption.9}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Optimization for three layers. The light field has an angular resolution of $9\times 9$ views.\relax }}{11}{figure.caption.10}}
\newlabel{fig:legotruck_artefacts_r=0}{{9}{11}{Optimization for three layers. The light field has an angular resolution of $9\times 9$ views.\relax }{figure.caption.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Optimization for three layers. The light field has an angular resolution of $9\times 9$ views.\relax }}{12}{figure.caption.11}}
\@writefile{toc}{\contentsline {section}{\numberline {8}Fixing the artefacts that occur in the reconstruction}{13}{section.8}}
\newlabel{fig:intersections_and_weights_overview}{{11a}{13}{Ray (red) coming from a pixel on layer $s^2$ intersecting the sensor plane $x$ and the topmost layer $s^1$. \relax }{figure.caption.12}{}}
\newlabel{sub@fig:intersections_and_weights_overview}{{a}{13}{Ray (red) coming from a pixel on layer $s^2$ intersecting the sensor plane $x$ and the topmost layer $s^1$. \relax }{figure.caption.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Calculation of the intersections and weights.\relax }}{13}{figure.caption.12}}
\newlabel{fig:intersections_and_weights}{{11}{13}{Calculation of the intersections and weights.\relax }{figure.caption.12}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.1}Comparison of the three methods implemented so far}{13}{subsection.8.1}}
\newlabel{fig:normalization_no_weights}{{12b}{14}{Row-normalization, box radius $0$, $w \equiv 1$.\relax }{figure.caption.13}{}}
\newlabel{sub@fig:normalization_no_weights}{{b}{14}{Row-normalization, box radius $0$, $w \equiv 1$.\relax }{figure.caption.13}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Reconstructions of the central view $\left (2, 2\right )$ from the $3 \times 3$ dice scene with different parameters.\relax }}{14}{figure.caption.13}}
\newlabel{fig:normalization_impact_comparison}{{12}{14}{Reconstructions of the central view $\left (2, 2\right )$ from the $3 \times 3$ dice scene with different parameters.\relax }{figure.caption.13}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.2}Interpolation on the sensor plane}{14}{subsection.8.2}}
\bibstyle{alpha}
\bibdata{lit}
\bibcite{LEVO_LFREN}{LH96}
\bibcite{WETZ_TOMO}{WLHR11}
\bibcite{WETZ_TENS}{WLHR12}
\bibcite{CONV_SART}{Yan10}
